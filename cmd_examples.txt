usage: pretrain_gpt.py [-h] [--num-layers NUM_LAYERS] [--encoder-num-layers ENCODER_NUM_LAYERS] [--decoder-num-layers DECODER_NUM_LAYERS] [--hidden-size HIDDEN_SIZE] [--ffn-hidden-size FFN_HIDDEN_SIZE]
                       [--num-attention-heads NUM_ATTENTION_HEADS] [--kv-channels KV_CHANNELS] [--group-query-attention] [--num-query-groups NUM_QUERY_GROUPS] [--max-position-embeddings MAX_POSITION_EMBEDDINGS]
                       [--position-embedding-type {learned_absolute,rope}] [--use-rotary-position-embeddings] [--rotary-percent ROTARY_PERCENT] [--rotary-interleaved]
                       [--rotary-seq-len-interpolation-factor ROTARY_SEQ_LEN_INTERPOLATION_FACTOR] [--no-position-embedding] [--make-vocab-size-divisible-by MAKE_VOCAB_SIZE_DIVISIBLE_BY] [--normalization {LayerNorm,RMSNorm}]
                       [--norm-epsilon NORM_EPSILON] [--apply-layernorm-1p] [--apply-residual-connection-post-layernorm] [--openai-gelu] [--squared-relu] [--swiglu] [--onnx-safe ONNX_SAFE] [--bert-no-binary-head]
                       [--untie-embeddings-and-output-weights] [--attention-dropout ATTENTION_DROPOUT] [--hidden-dropout HIDDEN_DROPOUT] [--weight-decay WEIGHT_DECAY] [--start-weight-decay START_WEIGHT_DECAY]
                       [--end-weight-decay END_WEIGHT_DECAY] [--weight-decay-incr-style {constant,linear,cosine}] [--clip-grad CLIP_GRAD] [--adam-beta1 ADAM_BETA1] [--adam-beta2 ADAM_BETA2] [--adam-eps ADAM_EPS]
                       [--sgd-momentum SGD_MOMENTUM] [--micro-batch-size MICRO_BATCH_SIZE] [--batch-size BATCH_SIZE] [--global-batch-size GLOBAL_BATCH_SIZE] [--rampup-batch-size [RAMPUP_BATCH_SIZE ...]]
                       [--recompute-activations] [--recompute-granularity {full,selective}] [--no-check-for-nan-in-loss-and-grad] [--distribute-saved-activations] [--recompute-method {uniform,block}]
                       [--recompute-num-layers RECOMPUTE_NUM_LAYERS] [--no-clone-scatter-output-in-embedding] [--profile] [--profile-step-start PROFILE_STEP_START] [--profile-step-end PROFILE_STEP_END]
                       [--profile-ranks PROFILE_RANKS [PROFILE_RANKS ...]] [--tp-comm-overlap] [--tp-comm-overlap-cfg TP_COMM_OVERLAP_CFG] [--disable-tp-comm-overlap-ag] [--disable-tp-comm-overlap-rs]
                       [--disable-tp-comm-bulk-dgrad] [--disable-tp-comm-bulk-wgrad] [--use-cpu-initialization] [--empty-unused-memory-level {0,1,2}] [--checkpoint-activations] [--train-iters TRAIN_ITERS]
                       [--train-samples TRAIN_SAMPLES] [--log-interval LOG_INTERVAL] [--exit-interval EXIT_INTERVAL] [--exit-duration-in-mins EXIT_DURATION_IN_MINS] [--exit-signal-handler] [--tensorboard-dir TENSORBOARD_DIR]
                       [--no-masked-softmax-fusion] [--no-bias-gelu-fusion] [--no-bias-swiglu-fusion] [--no-bias-dropout-fusion] [--no-rope-fusion] [--use-flash-attn] [--disable-bias-linear] [--add-qkv-bias]
                       [--optimizer {adam,sgd}] [--dataloader-type {single,cyclic,external}] [--no-async-tensor-model-parallel-allreduce] [--no-persist-layer-norm] [--sequence-parallel] [--no-gradient-accumulation-fusion]
                       [--use-mcore-models] [--manual-gc] [--manual-gc-interval MANUAL_GC_INTERVAL] [--no-manual-gc-eval] [--disable-tp-comm-split-ag] [--disable-tp-comm-split-rs] [--seed SEED] [--data-parallel-random-init]
                       [--init-method-std INIT_METHOD_STD] [--init-method-xavier-uniform] [--lr LR] [--lr-decay-style {constant,linear,cosine,inverse-square-root}] [--lr-decay-iters LR_DECAY_ITERS]
                       [--lr-decay-samples LR_DECAY_SAMPLES] [--lr-warmup-fraction LR_WARMUP_FRACTION] [--lr-warmup-iters LR_WARMUP_ITERS] [--lr-warmup-samples LR_WARMUP_SAMPLES] [--lr-warmup-init LR_WARMUP_INIT]
                       [--warmup WARMUP] [--min-lr MIN_LR] [--override-opt_param-scheduler] [--use-checkpoint-opt_param-scheduler] [--decoupled-lr DECOUPLED_LR] [--decoupled-min-lr DECOUPLED_MIN_LR] [--save SAVE]
                       [--save-interval SAVE_INTERVAL] [--no-save-optim] [--no-save-rng] [--load LOAD] [--no-load-optim] [--no-load-rng] [--finetune] [--pretrained-checkpoint PRETRAINED_CHECKPOINT] [--ckpt-step CKPT_STEP]
                       [--no-initialization] [--use-checkpoint-args] [--exit-on-missing-checkpoint] [--use-dist-ckpt] [--auto-detect-ckpt-format] [--dist-ckpt-format {zarr,torch_dist}] [--ckpt-fully-parallel-save] [--fp16]
                       [--bf16] [--loss-scale LOSS_SCALE] [--initial-loss-scale INITIAL_LOSS_SCALE] [--min-loss-scale MIN_LOSS_SCALE] [--loss-scale-window LOSS_SCALE_WINDOW] [--hysteresis HYSTERESIS]
                       [--fp32-residual-connection] [--apply-query-key-layer-scaling] [--attention-softmax-in-fp32] [--accumulate-allreduce-grads-in-fp32] [--fp16-lm-cross-entropy]
                       [--tensor-model-parallel-size TENSOR_MODEL_PARALLEL_SIZE] [--pipeline-model-parallel-size PIPELINE_MODEL_PARALLEL_SIZE] [--pipeline-model-parallel-split-rank PIPELINE_MODEL_PARALLEL_SPLIT_RANK]
                       [--model-parallel-size MODEL_PARALLEL_SIZE] [--num-layers-per-virtual-pipeline-stage NUM_LAYERS_PER_VIRTUAL_PIPELINE_STAGE] [--no-overlap-p2p-communication] [--distributed-backend {nccl,gloo}]
                       [--distributed-timeout-minutes DISTRIBUTED_TIMEOUT_MINUTES] [--overlap-grad-reduce] [--no-delay-grad-reduce] [--overlap-param-gather] [--delay-param-gather] [--no-scatter-gather-tensors-in-pipeline]
                       [--use-ring-exchange-p2p] [--local_rank LOCAL_RANK] [--lazy-mpu-init LAZY_MPU_INIT] [--standalone-embedding-stage] [--use-distributed-optimizer] [--context-parallel-size CONTEXT_PARALLEL_SIZE]
                       [--nccl-communicator-config-path NCCL_COMMUNICATOR_CONFIG_PATH] [--eval-iters EVAL_ITERS] [--eval-interval EVAL_INTERVAL] [--test-mode] [--skip-train] [--data-path [DATA_PATH ...]] [--split SPLIT]
                       [--train-data-path [TRAIN_DATA_PATH ...]] [--valid-data-path [VALID_DATA_PATH ...]] [--test-data-path [TEST_DATA_PATH ...]] [--data-cache-path DATA_CACHE_PATH] [--no-mmap-bin-files] [--mock-data]
                       [--vocab-size VOCAB_SIZE] [--vocab-file VOCAB_FILE] [--merge-file MERGE_FILE] [--vocab-extra-ids VOCAB_EXTRA_IDS] [--seq-length SEQ_LENGTH] [--encoder-seq-length ENCODER_SEQ_LENGTH]
                       [--decoder-seq-length DECODER_SEQ_LENGTH] [--retriever-seq-length RETRIEVER_SEQ_LENGTH] [--sample-rate SAMPLE_RATE] [--mask-prob MASK_PROB] [--short-seq-prob SHORT_SEQ_PROB] [--num-workers NUM_WORKERS]
                       [--tokenizer-type {BertWordPieceLowerCase,BertWordPieceCase,GPT2BPETokenizer,SentencePieceTokenizer,GPTSentencePieceTokenizer,Llama2Tokenizer,NullTokenizer}] [--tokenizer-model TOKENIZER_MODEL]
                       [--reset-position-ids] [--reset-attention-mask] [--eod-mask-loss] [--no-create-attention-mask-in-dataloader] [--adlr-autoresume] [--adlr-autoresume-interval ADLR_AUTORESUME_INTERVAL]
                       [--ict-head-size ICT_HEAD_SIZE] [--biencoder-projection-dim BIENCODER_PROJECTION_DIM] [--biencoder-shared-query-context-model] [--ict-load ICT_LOAD] [--bert-load BERT_LOAD]
                       [--titles-data-path TITLES_DATA_PATH] [--query-in-block-prob QUERY_IN_BLOCK_PROB] [--use-one-sent-docs] [--evidence-data-path EVIDENCE_DATA_PATH]
                       [--retriever-report-topk-accuracies RETRIEVER_REPORT_TOPK_ACCURACIES [RETRIEVER_REPORT_TOPK_ACCURACIES ...]] [--retriever-score-scaling] [--block-data-path BLOCK_DATA_PATH]
                       [--embedding-path EMBEDDING_PATH] [--indexer-batch-size INDEXER_BATCH_SIZE] [--indexer-log-interval INDEXER_LOG_INTERVAL] [--num-classes NUM_CLASSES] [--img-h IMG_H] [--img-w IMG_W]
                       [--num-channels NUM_CHANNELS] [--patch-dim PATCH_DIM] [--classes-fraction CLASSES_FRACTION] [--data-per-class-fraction DATA_PER_CLASS_FRACTION] [--no-data-sharding] [--head-lr-mult HEAD_LR_MULT]
                       [--vision-pretraining] [--vision-pretraining-type {classify,inpaint,dino}] [--vision-backbone-type {vit,mit,swin}] [--swin-backbone-type {tiny,base,h3}] [--mask-type {random,row}]
                       [--mask-factor MASK_FACTOR] [--iter-per-epoch ITER_PER_EPOCH] [--dino-local-img-size DINO_LOCAL_IMG_SIZE] [--dino-local-crops-number DINO_LOCAL_CROPS_NUMBER]
                       [--dino-head-hidden-size DINO_HEAD_HIDDEN_SIZE] [--dino-bottleneck-size DINO_BOTTLENECK_SIZE] [--dino-freeze-last-layer DINO_FREEZE_LAST_LAYER] [--dino-norm-last-layer]
                       [--dino-warmup-teacher-temp DINO_WARMUP_TEACHER_TEMP] [--dino-teacher-temp DINO_TEACHER_TEMP] [--dino-warmup-teacher-temp-epochs DINO_WARMUP_TEACHER_TEMP_EPOCHS] [--qk-layernorm]
                       [--expert-model-parallel-size EXPERT_MODEL_PARALLEL_SIZE] [--num-experts NUM_EXPERTS] [--moe-router-load-balancing-type {aux_loss,sinkhorn,none}] [--moe-router-topk MOE_ROUTER_TOPK]
                       [--moe-grouped-gemm] [--moe-aux-loss-coeff MOE_AUX_LOSS_COEFF] [--moe-z-loss-coeff MOE_Z_LOSS_COEFF] [--moe-input-jitter-eps MOE_INPUT_JITTER_EPS] [--moe-token-dropping]
                       [--moe-token-dispatcher-type {allgather,alltoall}] [--moe-per-layer-logging] [--log-params-norm] [--log-num-zeros-in-grad] [--log-throughput] [--log-progress] [--timing-log-level {0,1,2}]
                       [--no-barrier-with-level-1-timing] [--timing-log-option {max,minmax,all}] [--tensorboard-log-interval TENSORBOARD_LOG_INTERVAL] [--tensorboard-queue-size TENSORBOARD_QUEUE_SIZE]
                       [--log-timers-to-tensorboard] [--log-batch-size-to-tensorboard] [--no-log-learnig-rate-to-tensorboard] [--no-log-loss-scale-to-tensorboard] [--log-validation-ppl-to-tensorboard]
                       [--log-memory-to-tensorboard] [--log-world-size-to-tensorboard] [--wandb-project WANDB_PROJECT] [--wandb-exp-name WANDB_EXP_NAME] [--wandb-save-dir WANDB_SAVE_DIR] [--enable-one-logger]
                       [--one-logger-project ONE_LOGGER_PROJECT] [--one-logger-entity ONE_LOGGER_ENTITY] [--one-logger-run-name ONE_LOGGER_RUN_NAME]
                       [--inference-batch-times-seqlen-threshold INFERENCE_BATCH_TIMES_SEQLEN_THRESHOLD] [--max-tokens-to-oom MAX_TOKENS_TO_OOM] [--output-bert-embeddings] [--bert-embedder-type {megatron,huggingface}]
                       [--fp8-format {e4m3,hybrid}] [--fp8-margin FP8_MARGIN] [--fp8-interval FP8_INTERVAL] [--fp8-amax-history-len FP8_AMAX_HISTORY_LEN] [--fp8-amax-compute-algo {most_recent,max}] [--no-fp8-wgrad]
                       [--transformer-impl {local,transformer_engine}] [--retro-project-dir RETRO_PROJECT_DIR] [--retro-add-retriever] [--retro-cyclic-train-iters RETRO_CYCLIC_TRAIN_ITERS]
                       [--retro-encoder-layers RETRO_ENCODER_LAYERS] [--retro-encoder-hidden-dropout RETRO_ENCODER_HIDDEN_DROPOUT] [--retro-encoder-attention-dropout RETRO_ENCODER_ATTENTION_DROPOUT]
                       [--retro-num-neighbors RETRO_NUM_NEIGHBORS] [--retro-num-retrieved-chunks RETRO_NUM_RETRIEVED_CHUNKS] [--retro-attention-gate RETRO_ATTENTION_GATE] [--retro-no-verify-neighbor-count]
                       [--spec [SPEC ...]] [--yaml-cfg YAML_CFG]