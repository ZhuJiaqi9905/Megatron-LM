/opt/conda/bin/python3  -u -m varuna.launcher --gpus_per_server 1   --total_gpus 16   --node_rank 2 --nservers 16 --master_addr 172.21.0.91 --nstages 2 --batch_size 1024 --chunk_size 1 --code_dir /workspace/Megatron-LM-varuna pretrain_gpt2.py --num-layers 24 --hidden-size 1024 --num-attention-heads 16 --seq-length 512 --max-position-embeddings 512 --train-iters 18750 --lr-decay-iters 18750 --save /mnt/gpu-91/varuna/checkpoints/gpt3_350M --data-path /mnt/gpu-91/dataset/gpt-dataset-simplewiki/my-gpt2_text_document --vocab-file /mnt/gpu-91/dataset/gpt2-vocab.json --merge-file /mnt/gpu-91/dataset/gpt2-merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 100 --save-interval 5 --eval-interval 1000 --use-cpu-initialization --eval-iters 5 --varuna --fp16
