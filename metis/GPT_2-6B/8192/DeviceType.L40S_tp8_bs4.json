{"model": {"model_name": "GPT_2-6B", "num_layers": 34, "parameters": {"total_parameters_bytes": 11119165440, "parameters_per_layer_bytes": [524288000, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 314705920, 524288000]}}, "execution_time": {"total_time_ms": 16030.6, "forward_backward_time_ms": 15987.56, "batch_generator_time_ms": 90.63, "layernorm_grads_all_reduce_time_ms": 8.860000000000001, "embedding_grads_all_reduce_time_ms": 0.10000000000000002, "optimizer_time_ms": 14.496666666666668, "layer_compute_total_ms": [154.24369140625, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 483.59966796875, 164.07875]}, "execution_memory": {"layer_memory_total_mb": [1644.0, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 1248.03125, 2250.0], "total_memory": 43831.0}}